{
    "revision": "35370f967f248445f51fb1c2e2814309a8403f00",
    "platform": "github-actions-selfhosted",
    "result": [
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_off-1000]",
            "total_duration": 118.54266717936844,
            "data": [
                {
                    "name": "run_duration",
                    "value": 118.33850906789303,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.088981628417969,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 12.536743490105001,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 4.845735453895253,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 1.1635086527094245,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.1163292458140344,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.11994426404854668,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_on-1000]",
            "total_duration": 193.04112360160798,
            "data": [
                {
                    "name": "run_duration",
                    "value": 191.842042285949,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.09600830078125,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 13.873762040862239,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 2.723215701686468,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 0.9151816051453352,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.12057219044478654,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.08592756851766936,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[vanilla]",
            "total_duration": 15.780758290551603,
            "data": [
                {
                    "name": "run",
                    "value": 15.76510767173022,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_size",
                    "value": 260.681435585022,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "wal_size",
                    "value": 32.0,
                    "unit": "MB",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[neon]",
            "total_duration": 11.658352011814713,
            "data": [
                {
                    "name": "run",
                    "value": 11.61396305821836,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "pageserver_writes",
                    "value": 688,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "size",
                    "value": 400.85205078125,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_uploaded",
                    "value": 401.2421875,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "num_files_uploaded",
                    "value": 26,
                    "unit": "",
                    "report": "lower_is_better"
                }
            ]
        }
    ]
}