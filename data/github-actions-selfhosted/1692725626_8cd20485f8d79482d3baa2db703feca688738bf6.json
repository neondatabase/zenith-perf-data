{
    "revision": "8cd20485f8d79482d3baa2db703feca688738bf6",
    "platform": "github-actions-selfhosted",
    "result": [
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_off-1000]",
            "total_duration": 96.20380415700492,
            "data": [
                {
                    "name": "run_duration",
                    "value": 95.26503211499949,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.1015625,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 9.869388459858142,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 5.996198531317909,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 12.836920178990113,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.31547678763059617,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 1.4874180597426672,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_on-1000]",
            "total_duration": 134.09000152899534,
            "data": [
                {
                    "name": "run_duration",
                    "value": 132.89946805000363,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.095550537109375,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 10.955897567863751,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 5.240728089772486,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 0.5252361230086535,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.1343396096608712,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.051863181904395685,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[vanilla]",
            "total_duration": 9.497380204993533,
            "data": [
                {
                    "name": "run",
                    "value": 9.482879128001514,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_size",
                    "value": 260.681435585022,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "wal_size",
                    "value": 32.0,
                    "unit": "MB",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[neon]",
            "total_duration": 12.43423882999923,
            "data": [
                {
                    "name": "run",
                    "value": 12.382583255006466,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "pageserver_writes",
                    "value": 1029,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "size",
                    "value": 400.87548828125,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_uploaded",
                    "value": 401.234375,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "num_files_uploaded",
                    "value": 26,
                    "unit": "",
                    "report": "lower_is_better"
                }
            ]
        }
    ]
}