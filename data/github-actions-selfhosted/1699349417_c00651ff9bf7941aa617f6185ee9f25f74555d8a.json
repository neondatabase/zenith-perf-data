{
    "revision": "c00651ff9bf7941aa617f6185ee9f25f74555d8a",
    "platform": "github-actions-selfhosted",
    "result": [
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_off-1000]",
            "total_duration": 112.09031137079,
            "data": [
                {
                    "name": "run_duration",
                    "value": 110.97523380815983,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.101425170898438,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 9.589673753218218,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 5.893811967020156,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 0.7826973758637905,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.21607028482400853,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.0936056831444627,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_on-1000]",
            "total_duration": 166.01455569639802,
            "data": [
                {
                    "name": "run_duration",
                    "value": 165.12723913416266,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.102119445800781,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 12.088298913204309,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 4.586694848340579,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 0.5195315815508366,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.21868831946459763,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.07094999464640375,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[vanilla]",
            "total_duration": 9.617709886282682,
            "data": [
                {
                    "name": "run",
                    "value": 9.603203546255827,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_size",
                    "value": 260.681435585022,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "wal_size",
                    "value": 32.0,
                    "unit": "MB",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[neon]",
            "total_duration": 19.51453658938408,
            "data": [
                {
                    "name": "run",
                    "value": 19.40023187547922,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "pageserver_writes",
                    "value": 1717,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "size",
                    "value": 0.0,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_uploaded",
                    "value": 711.6796875,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "num_files_uploaded",
                    "value": 28,
                    "unit": "",
                    "report": "lower_is_better"
                }
            ]
        }
    ]
}