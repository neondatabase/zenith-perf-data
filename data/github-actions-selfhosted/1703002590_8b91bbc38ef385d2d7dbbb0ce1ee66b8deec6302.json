{
    "revision": "8b91bbc38ef385d2d7dbbb0ce1ee66b8deec6302",
    "platform": "github-actions-selfhosted",
    "result": [
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_off-1000]",
            "total_duration": 91.93161985743791,
            "data": [
                {
                    "name": "run_duration",
                    "value": 91.05494762584567,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 0.689875166863203,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.22157365640004476,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.13680052501812892,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.088821411132812,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 10.774586520352207,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 5.821612479596935,
                    "unit": "MB",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_on-1000]",
            "total_duration": 166.31105841789395,
            "data": [
                {
                    "name": "run_duration",
                    "value": 165.2674678331241,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.094711303710938,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 13.926670260545684,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 2.9033249257581875,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 0.8855167664587498,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.2203137590412927,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.13311792877628623,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[vanilla]",
            "total_duration": 13.462742630392313,
            "data": [
                {
                    "name": "run",
                    "value": 13.446185460314155,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_size",
                    "value": 260.704873085022,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "wal_size",
                    "value": 32.0,
                    "unit": "MB",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[neon]",
            "total_duration": 27.155094580724835,
            "data": [
                {
                    "name": "run",
                    "value": 27.08020861633122,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "pageserver_writes",
                    "value": 1717,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "size",
                    "value": 0.0,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_uploaded",
                    "value": 711.7265625,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "num_files_uploaded",
                    "value": 28,
                    "unit": "",
                    "report": "lower_is_better"
                }
            ]
        }
    ]
}