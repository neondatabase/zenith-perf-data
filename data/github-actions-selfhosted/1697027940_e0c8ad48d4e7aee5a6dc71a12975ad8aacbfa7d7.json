{
    "revision": "e0c8ad48d4e7aee5a6dc71a12975ad8aacbfa7d7",
    "platform": "github-actions-selfhosted",
    "result": [
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_off-1000]",
            "total_duration": 158.31605907157063,
            "data": [
                {
                    "name": "run_duration",
                    "value": 157.43260743655264,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.093238830566406,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 12.340445160106489,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 4.952554917629789,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 1.107943020761013,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.20678049222146735,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.1838729043704127,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_wal_backpressure.py::test_pgbench_intensive_init_workload[neon_on-1000]",
            "total_duration": 240.70042658783495,
            "data": [
                {
                    "name": "run_duration",
                    "value": 239.22844232991338,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_max",
                    "value": 15.09539794921875,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_avg",
                    "value": 14.047927503826237,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "lsn_write_lag_stdev",
                    "value": 2.583365655464242,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_max",
                    "value": 1.2052535004913807,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_avg",
                    "value": 0.1944596290921987,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "read_latency_stdev",
                    "value": 0.15204174117864247,
                    "unit": "s",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[vanilla]",
            "total_duration": 15.40933833643794,
            "data": [
                {
                    "name": "run",
                    "value": 15.393442008644342,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_size",
                    "value": 260.681435585022,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "wal_size",
                    "value": 32.0,
                    "unit": "MB",
                    "report": "lower_is_better"
                }
            ]
        },
        {
            "suit": "test_runner/performance/test_write_amplification.py::test_write_amplification[neon]",
            "total_duration": 24.48911409266293,
            "data": [
                {
                    "name": "run",
                    "value": 24.392206970602274,
                    "unit": "s",
                    "report": "lower_is_better"
                },
                {
                    "name": "pageserver_writes",
                    "value": 1717,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "size",
                    "value": 0.0,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "data_uploaded",
                    "value": 711.6796875,
                    "unit": "MB",
                    "report": "lower_is_better"
                },
                {
                    "name": "num_files_uploaded",
                    "value": 28,
                    "unit": "",
                    "report": "lower_is_better"
                }
            ]
        }
    ]
}